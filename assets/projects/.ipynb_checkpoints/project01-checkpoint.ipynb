{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 01: Exploring Wikipedia Page Metrics\n",
    "\n",
    "- **Due**: Thursday, 27 September 2018; 12:00pm\n",
    "- **Total Points**: 70\n",
    "    - correctly parsed list of authors, 15 points\n",
    "    - working functions, 20 points\n",
    "    - save and upload CSV file, 5 points\n",
    "    - interactive graphics, 15 points\n",
    "    - analysis, 15 points\n",
    "\n",
    "In this project, you'll work on a task similar to Tutorial-11 by\n",
    "extracting page metrics from a set of Wikipedia pages and analyzing\n",
    "the results. Please pick one of the following lists of pages to work\n",
    "with (I've picked these because the format is similiar to the American\n",
    "novelists; if you want to do something different just ask!):\n",
    "\n",
    "- https://en.wikipedia.org/wiki/List_of_Irish_writers\n",
    "- https://en.wikipedia.org/wiki/List_of_Chinese_writers\n",
    "- https://en.wikipedia.org/wiki/List_of_French-language_authors\n",
    "- https://en.wikipedia.org/wiki/List_of_Indian_writers\n",
    "- https://en.wikipedia.org/wiki/List_of_Black_British_writers\n",
    "\n",
    "Once you have picked your set of pages complete sections (1)-(5)\n",
    "below. Submit the Jupyter notebook within the project01 directory\n",
    "on GitHub along with your CSV file (please do not upload all of the JSON\n",
    "files). Also, make sure to upload the fully executed version of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 01: Grabbing the data\n",
    "\n",
    "In code blocks below (please add or delete blocks as needed), grab all of the\n",
    "Wikipedia pages for the writers on your list. Pay attention to any issues that\n",
    "arise in this process, such as needing the truncate the start or end of the list.\n",
    "Note that you will need to copy the `wiki.py` file into the directory where you\n",
    "put your project code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 02: Defining functions\n",
    "\n",
    "Here, unlike tutorial 11, we will develop a set of functions to help parse our\n",
    "Wikipedia data. I've filled in some of the details for you, but you'll need to\n",
    "fill in the details. \n",
    "\n",
    "Note that by default the functions will run, but return the same result for every\n",
    "page. The next section contains some code to help test you results.\n",
    "\n",
    "Also note that you should not need to modify `links_to_dataframe` or `wiki_page_metrics`,\n",
    "but you will need to change the remaining functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def links_to_dataframe(links):\n",
    "    \"\"\"Takes a list of links and returns a pandas data frame of metrics.\n",
    "    \n",
    "    You should not need to modify this function. It takes a list of all\n",
    "    the links that you want to study and returns a single pandas data frame\n",
    "    with all of the variables of interest.\n",
    "    \n",
    "    Args:\n",
    "        links: List of character strings indicating the pages to study.\n",
    "    Returns:\n",
    "        A pandas.DataFrame object with data about each page.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create initial empty lists\n",
    "    author_name = []\n",
    "    num_langs = []\n",
    "    num_links = []\n",
    "    num_chars = []\n",
    "    num_elinks = []\n",
    "    num_images = []\n",
    "    num_sections = []\n",
    "    \n",
    "    # Fill data for each links\n",
    "    import wiki\n",
    "    \n",
    "    for link in links:\n",
    "        data = wiki.get_wiki_json(link)\n",
    "        metrics = wiki_page_metrics(data)\n",
    "        author_name.append(metrics['author_name'])\n",
    "        num_langs.append(metrics['num_langs'])\n",
    "        num_links.append(metrics['num_links'])\n",
    "        num_chars.append(metrics['num_chars'])\n",
    "        num_elinks.append(metrics['num_elinks'])\n",
    "        num_images.append(metrics['num_images'])\n",
    "        num_sections.append(metrics['num_sections'])\n",
    "        \n",
    "    # Convert lists to DataFrame and return results\n",
    "    import collections\n",
    "\n",
    "    df = collections.OrderedDict()\n",
    "    df['author_name'] = author_name\n",
    "    df['url'] = links\n",
    "    df['num_langs'] = num_langs\n",
    "    df['num_links'] = num_links\n",
    "    df['num_chars'] = num_chars\n",
    "    df['num_elinks'] = num_elinks\n",
    "    df['num_images'] = num_images\n",
    "    df['num_sections'] = num_sections\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_page_metrics(data):\n",
    "    \"\"\"Takes JSON page data and returns notablility metrics from the page.\n",
    "    \n",
    "    You should not need to modify this function. It calls all of the other\n",
    "    metric functions, which you will need to modify and create.\n",
    "    \n",
    "    Args:\n",
    "        data: The raw page data from the function `wiki.get_wiki_json`.\n",
    "    Returns:\n",
    "        A dictionary containing metric data values.\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'author_name': page_title(data),\n",
    "        'num_langs': page_num_langs(data),\n",
    "        'num_links': page_num_links(data),\n",
    "        'num_chars': page_num_chars(data),\n",
    "        'num_elinks': page_num_elinks(data),\n",
    "        'num_images': page_num_images(data),\n",
    "        'num_sections': page_num_sections(data)\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_title(data):\n",
    "    \"\"\"Extract title from JSON data.\n",
    "    \"\"\"\n",
    "    return 'Taylor Arnold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_num_langs(data):\n",
    "    \"\"\"Extract number of language links from JSON data.\n",
    "    \"\"\"\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_num_links(data):\n",
    "    \"\"\"Extract number of internal links from JSON data.\n",
    "    \"\"\"\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_num_chars(data):\n",
    "    \"\"\"Extract length of text in characters from JSON data.\n",
    "    \"\"\"\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_num_elinks(data):\n",
    "    \"\"\"Extract number of external links from JSON data.\n",
    "    \"\"\"\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_num_images(data):\n",
    "    \"\"\"Extract number of images from JSON data.\n",
    "    \"\"\"\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_num_sections(data):\n",
    "    \"\"\"Extract number of images from JSON data.\n",
    "    \"\"\"\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 03: Test your code\n",
    "\n",
    "Use the code below to test whether you script works on these three American\n",
    "Novelists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_to_dataframe(['Mark_Twain', 'John_Updike', 'Margaret_Walker'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 04: Save results as CSV file\n",
    "\n",
    "Using the functions defined above, extract metadata for your list of authors\n",
    "using the `links_to_dataframe` function and save the results as a CSV file in\n",
    "the code below. You can call the file anything reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 05: Graphics and analysis\n",
    "\n",
    "In code blocks below, produce two interactive graphics. Above each graphic, provide\n",
    "a markdown cell that includes 4-5 sentences describing something interesting you found\n",
    "from each graphic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
