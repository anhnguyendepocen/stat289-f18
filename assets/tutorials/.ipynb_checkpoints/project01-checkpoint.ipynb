{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 01: Grab Wikipedia Page with HTTP\n",
    "\n",
    "- **Due**: Tuesday, 11 September 2018; 12:00pm\n",
    "- **Total Points**: 30\n",
    "    - correct docstrings, 10 points\n",
    "    - prints correct top terms, 10 points\n",
    "    - returns correct number of links, 10 points\n",
    "\n",
    "In this project you will create four functions that together pull a raw HTML\n",
    "page from Wikipeida and then performs two actions: (1) determines the 20 most\n",
    "frequent terms on the page and (2) counts and returns the number of links on\n",
    "the page. As this is the first assignment, I'll give you some template functions\n",
    "to work with and some test functions at the bottom of the page.\n",
    "\n",
    "You'll need to give a docstring for the function `process_page`. I have done \n",
    "this for you for the other three functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "You should fill in the code below to create a function that grabs data from\n",
    "Wikipedia. We have done almost all of these steps individually; this small\n",
    "project just asks you to put all of the pieces together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_website(title):\n",
    "    \"\"\"Return the contents of a Wikipedia page\n",
    "    \n",
    "    This takes the title, not the url, of a page on Wikipedia and\n",
    "    returns the results. You'll need to construct the URL and then\n",
    "    make use of the requests module to make this work. Note that you\n",
    "    **should** restrict the result to only range from the \"<body\" to\n",
    "    the \"<noscript>\" tag, as we did in Tutorial 06.\n",
    "    \n",
    "    Args:\n",
    "        title: title of the page as a string\n",
    "        \n",
    "    Returns:\n",
    "        A string containing the text of the page\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_words(text, num=10):\n",
    "    \"\"\"Finds top `num` words in the raw text\n",
    "    \n",
    "    This takes the text of the website, as produced by `get_wiki_website`\n",
    "    and returns the output of the `most_common` method from a Python\n",
    "    Collection. You will need to do all of the typical cleaning that we\n",
    "    did in Tutorial 06.\n",
    "    \n",
    "    Args:\n",
    "        text: string to parse words from\n",
    "        num: number of top words to return; default is 10\n",
    "        \n",
    "    Returns:\n",
    "        The output of the `most_common` method\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    \n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_num_links(text, num=10):\n",
    "    \"\"\"Counts number of internal Wikipedia links\n",
    "    \n",
    "    This function counts the number of internal links found in the text\n",
    "    of the Wikipedia page. You can do this by counting the number of times\n",
    "    the string '<a href=\"/wiki/' occurs in the text. This is relatively\n",
    "    straightforward, but requires the `re.findall` function and the\n",
    "    function `len` applied to the list returned as a result. We have not\n",
    "    yet done this in our tutorials.\n",
    "    \n",
    "    Args:\n",
    "        text: string to parse words from\n",
    "        num: number of top words to return; default is 10\n",
    "        \n",
    "    Returns:\n",
    "        The output of the `most_common` method\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    \n",
    "    return num_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(title):\n",
    "    \"\"\"\n",
    "    \n",
    "    You do not need to edit the code in this function, just create a proper\n",
    "    docstring!\n",
    "    \"\"\"\n",
    "    text = get_wiki_website(title)      # get raw text\n",
    "    \n",
    "    top_words = find_top_words(text)    # get top words and print results\n",
    "    print(top_words)      \n",
    "    \n",
    "    num_links = count_num_links(text)       # count number of links and return the result\n",
    "    return num_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "You can check that your functions perform correctly by trying the following tests.\n",
    "\n",
    "**Note: Wikipedia is constant changing; if there are any edits to the UR page, these\n",
    "tests will not produce the exact same results. That's okay. Just make sure your\n",
    "results are close.**\n",
    "\n",
    "The top words for the University of Richmond website should be given by this list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_top_words = [('the', 308), ('of', 239), ('richmond', 114), ('and', 114),\n",
    "                      ('university', 113), ('in', 109), ('to', 73), ('a', 72),\n",
    "                      ('college', 63), ('school', 57)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that with this code (it should print out `True`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = get_wiki_website(\"University_of_Richmond\")\n",
    "top_words = find_top_words(text)\n",
    "\n",
    "print(top_words == expected_top_words)\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be 367 links on the University of Richmond website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = get_wiki_website(\"University_of_Richmond\")\n",
    "num_links = count_num_links(text)\n",
    "\n",
    "print(num_links == 367)\n",
    "print(num_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `process_page` should return the count and print\n",
    "out the top words, both matching above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_page(\"University_of_Richmond\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, test that you get reasonable results on another page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_page(\"Data_science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
