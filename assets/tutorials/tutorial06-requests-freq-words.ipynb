{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 06: Using Requests and Regular Expressions to Count Words\n",
    "\n",
    "Here we use the requests library to actually grab web data from Wikipedia as an HTML page.\n",
    "Using the regular expressions you saw in the prior tutorial, you'll remove all of the special\n",
    "formatting and count the most frequent words found on the page. This will be our first chance\n",
    "to do something with the actual data from Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules\n",
    "\n",
    "To start, we will load both the `re` module and the `requests` module. The second\n",
    "is what we will use to extract websites into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a request\n",
    "\n",
    "We will start by all grabbing the Wikipedia webpage associated with the University\n",
    "of Richmond. At the end of the tutorial, you'll be able to grab a website of your\n",
    "own choosing. I suggest opening the Wikipedia page in another tab so that you can\n",
    "compare the website with the extracted code in Python.\n",
    "\n",
    "To make a \"request\" using the `requests` module, we use the function `get` and pass\n",
    "it the full URL to the page, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/University_of_Richmond'\n",
    "r = requests.get(url)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the object that is returned, called `r` here, does not\n",
    "print out anything resembling the actual website. Instead, we just get a\n",
    "message that should say `<Response [200]>` (if not, you have a problem; perhaps\n",
    "a network connectivity issue). What this means is that the request was processed\n",
    "and returned the [HTTP status code](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "of 200. This indicates that the request was processed with a status of OK; more\n",
    "verbosely:\n",
    "\n",
    "> Standard response for successful HTTP requests. The actual response will depend\n",
    "> on the request method used. In a GET request, the response will contain an entity\n",
    "> corresponding to the requested resource. In a POST request, the response will contain\n",
    "> an entity describing or containing the result of the action.\n",
    "\n",
    "The response given by the website contains a number of elements. For example, there\n",
    "is the \"HTTP header\" that contains metadata about the HTTP request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The part that we are most interested in, however, is the text of the response. This is\n",
    "given by the attribute `text`, which we can print out as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text above is written in a markup language called HTML; rendered in your browser it\n",
    "yields the pretty website that you are used to seeing when you navigate to Wikipedia.\n",
    "\n",
    "In Python, this text is just stored as a very long string object similar to the strings\n",
    "you saw in Tutorial 3. We will now make use of string methods and regular expression \n",
    "functions to process the string and extract the individual words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning HTML code\n",
    "\n",
    "To start, we will save the request text as a variable called `website`. Just\n",
    "to simplify the processing, in the code below I have also remove the first \n",
    "set of lines corresponding the HTML header and an embedded Javascript chunk \n",
    "at the bottom of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = r.text\n",
    "website = website[website.find(\"<body\"):website.find(\"<noscript>\")]\n",
    "print(website)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you scroll through some of the text below; the top is a bit noisy, but\n",
    "you should see the text of the page hidden within the HTML tags. \n",
    "\n",
    "Now, it's your turn to start writing some code. In the block below overwrite the variable\n",
    "`website` by removing all HTML tags from the original string. Print out the `website`\n",
    "variable at the end of the block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should already look a lot closer to the raw text on the website.\n",
    "Recall that using the function `print` makes newline characters look\n",
    "nice. It also makes a TAB (represented by the symbol `t`) appear nicely.\n",
    "To see this, look at the raw string `website` by runing the code below; mentally\n",
    "compare to the printed version above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now replace all copies of the special characters `\\n`, `\\r`, and `\\t`\n",
    "with a single space in the variable `website`. Make sure to save the result again\n",
    "as the variable `website`. (Note: You can do this with three seperate calls to\n",
    "`re.sub`; try to do it with just a single line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are really getting close to the raw text on the page!\n",
    "\n",
    "As a next step, use the string method `.lower()` to make the website\n",
    "all in lower case. This will help later so that words like \"School\"\n",
    "and \"school\" are not counted differently. Print out the result again\n",
    "just to check your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still a number of special formatting marks, as well as punctuation\n",
    "and other special characters, in the this text. As a simple solution, in the\n",
    "code block below write a call to the `re.sub` function that replaces anything\n",
    "that **is not** a lower case letter with a space. (Hint: you did this exact\n",
    "thing in Tutorial 5). Once again, print out the result at the end of the code\n",
    "block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step in cleaning the output, notice that from the cleaning process\n",
    "there are many places that have a long set of spaces inbetween them. Use a\n",
    "regular expression to convert any sequence of spaces into a single space. And\n",
    "again, print out the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should have a nice clear version of just the words in the Wikipedia\n",
    "page. Yay! See how awesome regular expression can be! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Words\n",
    "\n",
    "Now that we have the raw text as a single string, we will want to using the\n",
    "function `re.split` to split apart the individual words. Do this in the block\n",
    "below, saving the result as a variable called `words`; print out the words with\n",
    "the print function at the end of the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we move forward in the course, we will see a number of things that can be done with these\n",
    "words such as building predictive and generative models. For today, let's just find the most\n",
    "frequently used words on the page. To do this with a minimal amount of code, we will load a\n",
    "function called `Counter` from the module `collections`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you saved the result above as a variable called `words`, as instructed, the\n",
    "following code will then spit out the 30 most common words in the text along\n",
    "with their counts. You can of course change the number 30 to anything you would\n",
    "like, but 30 seems to be work well for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(words).most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these the words you would have expected to be the most common on the University\n",
    "of Richmond Wikipedia page? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping it all up\n",
    "\n",
    "In this tutorial I broke down all of the steps in requesting, cleaning, and counting\n",
    "the most frequent words from a page on Wikipedia. The entire process when combined\n",
    "requires only a total of about 10 lines. In the code block below I want you to put\n",
    "all of the steps together, with the page url at the top (here I put a new URL, the\n",
    "one to the page about Marxism). At the end of the block the 30 most common words on\n",
    "the page should show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Marxism'\n",
    "\n",
    "# Put all of your code from above here and remove this comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the code tested and working, try to input several other Wikipedia pages\n",
    "and begin exploring what you see in the data. (Note: This should now be easy as you have\n",
    "only to run a single block of code). Are there any interesting patterns or missing words\n",
    "that start to show up?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
