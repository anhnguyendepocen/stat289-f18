{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 24: Machine Learning in Python with scikit-learn\n",
    "\n",
    "Today we will replace our custom code for building predictive models with\n",
    "**sklearn**, a popular module for many tasks in machine learning. You'll \n",
    "find that most of the well-known predictive models exist in the module,\n",
    "and many others extend the same structures when implementing new models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the libraries\n",
    "\n",
    "We will make use of the three class modules, as well as **numpy**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wiki\n",
    "import iplot\n",
    "import wikitext\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert wiki.__version__ >= 6\n",
    "assert wikitext.__version__ >= 2\n",
    "assert iplot.__version__ >= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some data\n",
    "\n",
    "For today, we will once again take links from the \"important publications in\n",
    "philosophy\" page to build a corpus for prediction. We will make a `WikiCorpus`\n",
    "object to simplify the computation of metrics for the page. Below I have removed\n",
    "two pages that give our Windows users some trouble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "links = wikitext.get_internal_links('List_of_important_publications_in_philosophy')['ilinks']\n",
    "links.remove(\"What_Is_it_Like_to_Be_a_Bat?\")\n",
    "links.remove(\"What_is_Life?_(Schrödinger)\")\n",
    "links = np.random.permutation(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcorp = wikitext.WikiCorpus(links, num_clusters=15, num_topics=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we now extract the number of internal links on each page, whether\n",
    "the page is translated into German ('de'), and five predictor variables that we\n",
    "will try to use in constructing our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ilinks = wcorp.meta['num_ilinks'].values\n",
    "lan_version = np.array(['de' in x for x in wcorp.meta['langs']], dtype=np.int)\n",
    "\n",
    "num_sections = wcorp.meta['num_sections'].values\n",
    "num_images = wcorp.meta['num_images'].values\n",
    "num_elinks = wcorp.meta['num_elinks'].values\n",
    "num_langs = wcorp.meta['num_langs'].values\n",
    "num_chars = np.array([len(x) for x in wcorp.meta['doc'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor matrix\n",
    "\n",
    "Last time we somewhat awkwardly kep the five predictor variables seperate from one\n",
    "another. In my solutions for Tutorial 23, I put them all into a list, but this was\n",
    "still somewhat clunky. Now, let's combine them together using **numpy** in a a single\n",
    "matrix of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.stack([num_sections, num_images, num_elinks, num_langs, num_chars], axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This two-dimensional array of numbers should remind you of the term-frequency matrix that\n",
    "I showed when introducing the **gensim** module. The array is arranged so that it has one\n",
    "row for each sample of data and one column for each variable. There are few helpful things\n",
    "to know about how numpy arrays work. First, they have a shape attribue that us the dimensions\n",
    "of the array. Here, we have 734 rows and 5 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, to select a subset of the matrix we use a similar slicing notation that we saw in\n",
    "tutorial 4 and 9. However, now we need notation to describe both the rows and columns,\n",
    "which are seperated by a comma. A colon indicates that all rows/colums should be taken.\n",
    "Look at these examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0, :] # the first row, all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:3, :] # the first 3 rows and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:2, :2] # first 2 rows and first three columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slicing notation will be useful as we construct models from the data. For example,\n",
    "let's now create the training and testing responses and matricies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = num_ilinks[:325]\n",
    "y_test  = num_ilinks[325:]\n",
    "x_train = x[:325, :]\n",
    "x_test  = x[325:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 325 observations constitute the \"training\" set and the rest of the data\n",
    "(of about the same amount) as the \"testing\" set. We will use these throughout the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sklearn\n",
    "\n",
    "Now, on to actually using the sklearn module. We will see first how to build\n",
    "a linear regression, but the nice thing about sklearn is that a similar set of\n",
    "steps can be used to apply almost any algorithm to the data.\n",
    "\n",
    "Start by constructing an instance of the model you want to build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = sklearn.linear_model.LinearRegression()\n",
    "reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing out the model, as above, is not nessisary, but does show use all of the\n",
    "input choices available for our model.\n",
    "\n",
    "Next, call the `fit` method using the training data (the training matrix x followed\n",
    "by the response y) to learn the parameters of the model using the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this changes the model `reg` directly and we do not need to save the\n",
    "result. That is, sklearn uses an object oriented design.\n",
    "\n",
    "Now, if we call the `predict` method on a data matrix, predictions from the\n",
    "model are returned as a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see the coefficents in the model itself, call the `.coef_` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods — `fit`, `predict`, and `coef_` — exist for all sklearn estimators\n",
    "whenever they make sense for the given model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "A very popular variation of linear regression, called logistic regression, exists\n",
    "to work with classification tasks. The details are beyond our similar treatment today,\n",
    "but let's see how the model works. There are some extra features available for classification\n",
    "tasks in sklearn.\n",
    "\n",
    "Start by redefining the response variable to be whether a page appears in German:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = lan_version[:325]\n",
    "y_test  = lan_version[325:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, construct the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = sklearn.linear_model.LogisticRegression()\n",
    "logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fit it to the data (this work exactly the same as the regression problem):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we call the prediction function it will spit out predictions that\n",
    "are either 1 (page available in German) or 0 (page not available in German)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is great, and exactly what we often want when doing prediction tasks. In some\n",
    "situations, however, we do not want the predictions themselves but rather an estimate\n",
    "of the probability that an input has a page in German. To get that call the method\n",
    "`predict_proba` (here, showing just the first 10 samples for illustration):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.predict_proba(x_train)[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is the probability of observering a `0` and the second\n",
    "is the probability of observering a `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "There are also a number of helpful functions in sklearn for preprocessing our data\n",
    "as well as evaluating the results. Let's produce the predicted classes for the \n",
    "testing set from our Logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two metrics that I like to spend most of my time looking at. Namely,\n",
    "the confusion matrix (which shows how many items are mis-classified):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.confusion_matrix(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together, these give a good picture of how well the model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try another model\n",
    "\n",
    "Now, for some practice. Look at all of the available models from sklearn:\n",
    "\n",
    "- http://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "\n",
    "Pick something that seems interesting, and use this model to make predictions\n",
    "on the training set. Then, compute the confusion matrix and accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does your model outperform the Logitic example?\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For next time\n",
    "\n",
    "Next class we are going to learn how to build a predictive model using the \n",
    "words within the text (this is in many ways a much more interesting task and\n",
    "more insightful for our ability to analyzing the data). To do this, we need\n",
    "one more more module (it implements a new model, but does so in the style of\n",
    "sklearn). To install it, run the following in a terminal (macOS) or the \n",
    "Anaconda navigator (windows):\n",
    "\n",
    "```\n",
    "conda install -c conda-forge glmnet\n",
    "```\n",
    "\n",
    "Then, make sure that the library installs by running the following line. I\n",
    "am a bit worried that this library may give errors on some machines, so\n",
    "please check it today before you head out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glmnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
