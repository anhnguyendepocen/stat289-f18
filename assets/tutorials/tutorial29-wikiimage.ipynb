{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 29: Wikipedia image data\n",
    "\n",
    "This tutorial introduces the `wikiimage.py` module, which we can use to grab\n",
    "and process image data from Wikipedia pages. Start by reading in the module,\n",
    "as well as numpy and pylab (for plotting the images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import wiki\n",
    "import wikiimage\n",
    "import wikitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading image data from Wikipedia\n",
    "\n",
    "The `image_data_frame` takes a list of Wikipedia pages and returns a data frame object\n",
    "showing all of the images from the page. You can also supply the minimum and maximum \n",
    "allowed sizes of images. By default the function will download a local version of any\n",
    "images you do not yet have locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = wikiimage.image_data_frame(['Paris', 'London'], min_size=300)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the returned results include the page name, the path of the image, as well as\n",
    "a column called \"max_size\". The latter column gives the size of the largest dimension of\n",
    "the image (either the height or width)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the images in Python\n",
    "\n",
    "The `load_image` function takes the name of an image and returns a `PIL` object,\n",
    "a special image type that can be plotted in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = wikiimage.load_image(df.img.values[4])\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some Python code that prints all of the image in the data frame. Note\n",
    "that you may need to modify the line `plt.subplot(4, 3, ind + 1)` if you change\n",
    "the data. The 4 gives the number of columns in the plot and the 3 gives the number\n",
    "of rows. If you have more than 12 images, only the first 12 will be shown. You can\n",
    "also adjust the `plt.rcParams[\"figure.figsize\"] = (12, 16)` above to change the overall\n",
    "size of the print out (I find that I need to adjust this depending on my screen and\n",
    "the images in question)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, idx in enumerate(range(df.shape[0])):\n",
    "    try:\n",
    "        plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "        plt.subplot(4, 3, ind + 1)\n",
    "\n",
    "        img = wikiimage.load_image(df.iloc[idx]['img'])\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image embedding\n",
    "\n",
    "Last time we saw how the VGG19 model takes a 224-by-224 dimensional image and\n",
    "returns a list of 1000 probabilities giving predictions of what objects are\n",
    "located in the image. Here's the model once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "vgg19_full = VGG19(weights='imagenet')\n",
    "vgg19_full.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VGG19 model as described here is really only useful if we care about the 1000\n",
    "categories described in the ILSVRC competition. Why would this be important enough\n",
    "to include in the **keras** module? In and of itself, it really is not. The reason\n",
    "the model is so important is due to something called *transfer learning*.\n",
    "\n",
    "It turns out that if we apply only a subset of the layers, say all but the final layer\n",
    "of the model, the neural network serves as form of dimensionality reduction. Look at\n",
    "the model above; if we look at the output of the layer `fc2` this serves to project a\n",
    "`224 * 224 * 3`, or `150,528` dimensional object, into `4096` dimensional space. To\n",
    "produce such an embedding, I'll use keras to strip off the second to last layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "vgg_fc2 = Model(inputs=vgg19_full.input, outputs=vgg19_full.get_layer('fc2').output)\n",
    "vgg_fc2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can apply the model just as we did before, but the output now contains 4096\n",
    "dimensions. These dimensions, just like with PCA and t-SNE, do not have an explict\n",
    "meaning. The relationships between images in the embedding space, however, describe\n",
    "semantic relationships, which we will be able to explore shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "img = wikiimage.load_image(df.img.values[1], target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "y = vgg_fc2.predict(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings in wikiimage\n",
    "\n",
    "The wikiimage module contains the function `vgg19_embed` that performs\n",
    "embedding into the `fc2` layer. Conveniently, the embedding are cached\n",
    "so that you only need to construct them once (it can take a while to\n",
    "create the embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc2 = wikiimage.vgg19_embed(df.img.values)\n",
    "df_fc2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a numpy array with one row for each image and 4096 columns. Again, we will see how\n",
    "to use these in just a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk download\n",
    "\n",
    "As with the Wikipedia pages at the start of the semester, I do not want you to all have\n",
    "to wait a long time to download the images for today's class. Conveniently, we should be\n",
    "able to use the same bulk download function if we are clever about calling the \"language\"\n",
    "of the images \"img\" and the \"language\" of the embeddings \"embed\". Grab both of these here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki.bulk_download('impressionists-text', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki.bulk_download('impressionists-image', lang='img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki.bulk_download('impressionists-embed', lang='embed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring impressionists\n",
    "\n",
    "For today's tutorial, let's create a dataset of all the pages linked to from the \n",
    "impressionists and extract from these all of the images. Note: you should have almost\n",
    "all of these from the bulk download above. If it starts downloading a lot of stuff,\n",
    "something is wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "page_links = wikitext.get_internal_links(\"Impressionism\")['ilinks'] + [\"Impressionism\"]\n",
    "df = wikiimage.image_data_frame(page_links, download=True, min_size=224, max_size=750)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's grab the VGG19 embeddings for these images. This may take a minute or two,\n",
    "there is a lot to load, but should finish quickly as almost all of the embeddings should\n",
    "already have been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wikiart_fc2 = wikiimage.vgg19_embed(df.img.values)\n",
    "wikiart_fc2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally, let's see why these embeddings are so useful. Let's start with the image 700:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_img = 700\n",
    "img = wikiimage.load_image(df.iloc[start_img]['img'])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the distance in the 4096-dimensional embedding space of this image to all\n",
    "of the other images in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = np.sum(np.abs(wikiart_fc2 - wikiart_fc2[start_img, :]), 1)\n",
    "dists.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll sort these distances and get the indicies of all of the 24 closest images in this\n",
    "space (of course, the closest image will be image 700 itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(dists.flatten())[:24]\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see all of the images in order from closest to farthest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 36))\n",
    "for ind, i in enumerate(idx):\n",
    "    try:\n",
    "        plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "        plt.subplot(8, 3, ind + 1)\n",
    "\n",
    "        img = wikiimage.load_image(df.iloc[i]['img'])\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairly accurate, when you consider all of the image types in the corpus, no?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the embeddings\n",
    "\n",
    "The code below picks a randoming starting point and displays the closest 24 images in the\n",
    "`fc2` space. Run it multiple times, and record particularly interesting numbers. Where does\n",
    "it work well and where does it run into problems? Tell me about at least one number that\n",
    "worked better than you expected and one issue that it had trouble dealing with:\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_img = np.random.randint(0, df.shape[0])\n",
    "\n",
    "print(\"Grabbed image number {0:d}.\".format(start_img))\n",
    "print(df.iloc[start_img])\n",
    "\n",
    "dists = np.sum(np.abs(wikiart_fc2 - wikiart_fc2[start_img, :]), 1)\n",
    "idx = np.argsort(dists.flatten())[:24]\n",
    "plt.figure(figsize=(14, 36))\n",
    "\n",
    "for ind, i in enumerate(idx):\n",
    "    try:\n",
    "        plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "        plt.subplot(8, 3, ind + 1)\n",
    "\n",
    "        img = wikiimage.load_image(df.iloc[i]['img'])\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
