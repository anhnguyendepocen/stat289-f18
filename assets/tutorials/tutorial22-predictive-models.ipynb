{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 22: Predictive Models\n",
    "\n",
    "For the next 2.5 weeks, we will be looking at how to build predictive models,\n",
    "with a focus on text and image processing. It will be a nice self-contained\n",
    "introduction, but also a good introduction to my *MATH389: Introduction to\n",
    "Statistical Learning* course that is being offered this Spring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Is Predictive Modeling / \"Learning\"?\n",
    "\n",
    "Statistical learning, synonymous with machine learning, is the process\n",
    "of extracting knowledge from data automatically, usually with the goal\n",
    "of making predictions on new, unseen data.\n",
    "\n",
    "A classical example is a spam filter, for which a user labels incoming mails\n",
    "as either spam or not spam. A machine learning algorithm then \"learns\" a\n",
    "predictive model from data that distinguishes spam from normal emails, a\n",
    "model which can predict for new emails whether they are spam or not.\n",
    "\n",
    "Here are some explicit examples:\n",
    "\n",
    "- using physical characteristics of animals to predict whether\n",
    "they are carnivores\n",
    "- estimate how much a house is worth given properties such as\n",
    "number of bedrooms, square footage and its address\n",
    "- predict whether a flight will be delayed given the carrier,\n",
    "scheduled departure time, arrival and departure airports\n",
    "- a crime has been reported at a specific place and time in\n",
    "Chicago; what type of crime is it?\n",
    "- here is a picture of a flower, what kind of flower is it?\n",
    "- given two sentences of text, predict which President used it\n",
    "in a public speech\n",
    "- how many page views will a specific Wikipedia page receive\n",
    "tomorrow?\n",
    "\n",
    "And can look at some explicit examples of these models in\n",
    "the wild:\n",
    "\n",
    "- [Automated game playing](https://www.youtube.com/watch?v=qv6UVOQ0F44)\n",
    "- [Face Detection and Recognition](https://www.youtube.com/watch?v=QLybZt3cI_0)\n",
    "- [Sports Video Classification](https://www.youtube.com/watch?v=qrzQ_AB1DZk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Algorithms\n",
    "\n",
    "In my experience, most learning algorithms fall into one of\n",
    "two broad categories:\n",
    "\n",
    "- nearest neighbors (local): estimate values of new points by\n",
    "finding previously observed points close to the new ones\n",
    "- linear models (global): estimate weights for each parameter;\n",
    "classify new points by summing up these weights\n",
    "\n",
    "Within these classes, I typically find the need to use only\n",
    "some combination of the following four algorithms:\n",
    "\n",
    "1. k-nearest neighbors: a straightforward application of\n",
    "nearest neighbors\n",
    "1. gradient boosted trees: adaptively implement nearest\n",
    "neighbors by determining which directions \"matter\"\n",
    "1. elastic net: a linear model with controls on the sizes of the\n",
    "weights\n",
    "1. neural networks: iteratively apply collections of elastic\n",
    "nets to learn a hierarchy of increasingly complex weights\n",
    "\n",
    "If some of these concepts seem hazy at the moment, that is\n",
    "perfectly natural. We'll go into much more detail throughout\n",
    "the next few weeks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Approach\n",
    "\n",
    "Today I want you to be become familiar with the basic mechanics of building predictive\n",
    "models. Here is my rough schedule for the next few classes:\n",
    "\n",
    "- 2018-10-18 (today): mechanics of predictive models\n",
    "- 2018-10-23: Using matricies in predictive models; introduction to sklearn\n",
    "- 2018-10-25: unsupervised learning and dimensionality reduction\n",
    "- 2018-10-30: Neural networks I; introduction to keras\n",
    "- 2018-11-01: Neural networks II; application to Wikipedia\n",
    "\n",
    "That should take us to working on your final project for the semester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple model and example\n",
    "\n",
    "Let's consider an example here where we have two variables, the\n",
    "number of capital letters in a text message an a classification of\n",
    "whether the message is spam (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps = [0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 4, 5, 5, 6, 6, 8, 8]\n",
    "spam = [0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's consider a model that simply classifies a message as being spam based\n",
    "on a threshold for how many capital letters it contains:\n",
    "\n",
    "$$ f(caps) = \\begin{cases} 0, & caps \\leq \\alpha  \\\\ 1, & caps > \\alpha \\end{cases} $$\n",
    "\n",
    "For some threshold $\\alpha$. How might we select the best value of $\\alpha$? One\n",
    "approach would be to test a bunch of values and determine what the best value is.\n",
    "\n",
    "So, consider all of the sensible values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_vals = list(range(0, 9))\n",
    "alpha_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can test for each value how many predictions are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alpha_vals:\n",
    "    error = []\n",
    "    for x, y in zip(caps, spam):\n",
    "        error.append(int(int(x > alpha) == y))\n",
    "    print(\"alpha={0:d}  percent correct={1:f}\".format(alpha, sum(error) / len(error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the best choice appears to by predicting anything with more than 1 capital letter\n",
    "equal to \"spam\" and otherwise assuming the message is not spam. It appears that we will\n",
    "be correct 72.2% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "\n",
    "There is one way we are cheating in this simple example. We are using the same dataset\n",
    "to pick the value of $\\alpha$ that we are using to validate that it is a good choice.\n",
    "This doesn't matter very much here, but becomes an issue when comparing models of different\n",
    "complexities. It will always seem — if we use the approach here — that a more complex model\n",
    "is better.\n",
    "\n",
    "A common method to avoid this issue is to split the dataset into two groups:\n",
    "\n",
    "1. A *training* set, which is used to select the parameters of the model (e.g., the $\\alpha$ above).\n",
    "2. A *testing* set, which is use to test how well a model performs on new data.\n",
    "\n",
    "In some cases you may create these datasets yourself; in others, they may be given to you\n",
    "by an external source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification vs Regression\n",
    "\n",
    "In the spam example, the thing we were trying to predict was a categorical variable.\n",
    "It has just two values, 'spam' and 'not spam', and we want to guess which of these\n",
    "two states a new message belongs to. There are also other prediction tasks that involve\n",
    "predicting a continuous variable. For example, predicting the price of a house. The\n",
    "first type of problem is called *classsification* and the second are often called\n",
    "*regression*. The biggest difference between these for us will be how we measure how\n",
    "good a model is at predicting the response. For classification, just computing the\n",
    "percentage of correct guesses is a good start. For regression typically we use absolute\n",
    "error:\n",
    "\n",
    "$$ | y - \\widehat{y} | $$\n",
    "\n",
    "Or squared error:\n",
    "\n",
    "$$ | y - \\widehat{y} |^2 $$\n",
    "\n",
    "Different choices lead to different models, something that we discuss in depth in MATH389."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "\n",
    "One Python library that will be very important useful for us in predictive models\n",
    "is **numpy**. I've already used this a bit in the python files created for the class,\n",
    "but we haven't seen them directly yet. I'll explain more on Tuesday, but here is a\n",
    "very minimal introduction.\n",
    "\n",
    "Typically, numpy is imported as the abbrevition **np**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key function for us here is called `np.array`. It converts a Python list into\n",
    "a numpy array. At first it will not appear that much has happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps = np.array(caps)\n",
    "caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = np.array(spam)\n",
    "spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, the big difference is that we can now perform vector arithmetic on the data. That is,\n",
    "we can operate on the object as a whole without needing to write a bunch of `for` loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam / (caps + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also a bunch of numeric functions that operate on an entire vector,\n",
    "such as `np.mean`, `np.log`, and `np.round`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, here is how we would re-write the code to check for the alpha values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alpha_vals:\n",
    "    error = np.mean((caps > alpha) == spam)\n",
    "    print(\"alpha={0:d}  percent correct={1:f}\".format(alpha, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the whole, this is quite a bit easier to write and read. This will be even more important,\n",
    "as we will see, when building more complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
