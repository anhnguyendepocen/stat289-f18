{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 25: Predicting with Words â€” The Elastic Net\n",
    "\n",
    "Today, we will learn how to build predictive models that classify textual\n",
    "documents by the words used in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading modules\n",
    "\n",
    "Start by loading our standard modules and make sure that everything is working\n",
    "as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"d8c3b4c5-22f0-48d8-bf6b-392481f55928\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"d8c3b4c5-22f0-48d8-bf6b-392481f55928\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"d8c3b4c5-22f0-48d8-bf6b-392481f55928\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'd8c3b4c5-22f0-48d8-bf6b-392481f55928' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"d8c3b4c5-22f0-48d8-bf6b-392481f55928\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"d8c3b4c5-22f0-48d8-bf6b-392481f55928\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"d8c3b4c5-22f0-48d8-bf6b-392481f55928\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'd8c3b4c5-22f0-48d8-bf6b-392481f55928' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"d8c3b4c5-22f0-48d8-bf6b-392481f55928\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wiki\n",
    "import iplot\n",
    "import wikitext\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "import glmnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert wiki.__version__ >= 6\n",
    "assert wikitext.__version__ >= 3\n",
    "assert iplot.__version__ >= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Our dataset here will be the pages linkined to from the\n",
    "[List of American novelists](https://en.wikipedia.org/wiki/List_of_American_novelists) and\n",
    "[List of poets from the United States](https://en.wikipedia.org/wiki/List_of_poets_from_the_United_States).\n",
    "Get the pages by grabing the bulk download from my website to speed things up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wiki.bulk_download('novel-poem', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below constructs seperate lists of novelists and poets, making sure\n",
    "to remove anyone on both lists. Finally it constructs an output vector `y_vals`\n",
    "that is 0 for authors and 1 for poets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data = wiki.get_wiki_json(\"List_of_American_novelists\")\n",
    "data_html = data['text']['*']\n",
    "authors = re.findall('<li><a href=\"/wiki/([^\"]+)\"', data_html)\n",
    "nov_authors = authors[:(authors.index('Leane_Zugsmith') + 1)]\n",
    "\n",
    "data = wiki.get_wiki_json(\"List_of_poets_from_the_United_States\")\n",
    "data_html = data['text']['*']\n",
    "authors = re.findall('<li><a href=\"/wiki/([^\"]+)\"', data_html)\n",
    "poe_authors = authors[:(authors.index('Louis_Zukofsky') + 1)]\n",
    "\n",
    "nov_authors = list(set(nov_authors) - set(poe_authors))\n",
    "poe_authors = list(set(poe_authors) - set(nov_authors))\n",
    "links = nov_authors + poe_authors\n",
    "\n",
    "y_vals = np.array([0] * len(nov_authors) + [1] * len(poe_authors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create a `wcorp` object to wrap up all of the information we need for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcorp = wikitext.WikiCorpus(links, num_clusters=15, num_topics=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual training data\n",
    "\n",
    "Recall that the `WikiCorpus` object has a function for returning the term\n",
    "frequency matrix. Here, we grab the sparse version of the matrix because it\n",
    "is much smaller and can be passed directly to most sklearn algorithms. Here,\n",
    "it should have over 18k rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2829, 18603)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_mat = wcorp.sparse_tf().transpose()\n",
    "tf_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, it will be useful to grab the names of the words in each column\n",
    "(here, we print out the first 100 terms):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1850', '1867', '1869', '1870s', '1878', '1885', '1886', '1890',\n",
       "       '1922', '24', '31', 'accounts', 'aldrich', 'appalachia',\n",
       "       'appalachian', 'appleton', 'atlantic', 'attended', 'bailey',\n",
       "       'battle', 'begun', 'bret', 'buried', 'celebrated', 'cemetery',\n",
       "       'characters', 'charles', 'childhood', 'citation', 'civil',\n",
       "       'closely', 'colonel', 'color', 'compared', 'considered', 'contact',\n",
       "       'contributing', 'cotton', 'creating', 'cumberland', 'death',\n",
       "       'editor', 'eliot', 'evergreen', 'fact', 'family', 'father',\n",
       "       'favorably', 'female', 'fiction', 'fifteen', 'finishing', 'fought',\n",
       "       'george', 'grandfather', 'great', 'hardy', 'harte', 'institute',\n",
       "       'january', 'jewett', 'journal', 'july', 'knoxville', 'lawyer',\n",
       "       'literature', 'lived', 'local', 'location', 'louis', 'mary',\n",
       "       'monthly', 'mountain', 'mountains', 'murfreesboro', 'named',\n",
       "       'nashville', 'necessity', 'needed', 'negative', 'novel', 'novels',\n",
       "       'number', 'opportunity', 'orne', 'pen', 'people', 'philadelphia',\n",
       "       'plantation', 'post', 'reading', 'realism', 'region', 'reinforce',\n",
       "       'resort', 'resorts', 'returning', 'revolutionary', 'sarah',\n",
       "       'school'], dtype='<U18')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = wcorp.terms()\n",
    "words[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, consider using the matrix `tf_mat` in a predictive model. Here it has 18k+ columns; \n",
    "in general, it is impossible to learn 18k parameters (as in a linear regression) \n",
    "with only 2800 observations. We need a method that is able to handle such models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net\n",
    "\n",
    "Consider a simple linear regression model. We have mentioned that the the ordinary\n",
    "least squares estimator is defined by minimizing the sum of squared residuals:\n",
    "    \n",
    "$$ \\text{LEAST SQUARES} \\rightarrow \\arg\\min_{a, b} \\left\\{ \\sum_i \\left( y_i - a - b \\cdot x_i \\right)^2  \\right\\}$$\n",
    "\n",
    "The lasso estimator modifies this slightly by adding a *penalty* term the entices\n",
    "the model to make the slove parameter smaller:\n",
    "\n",
    "$$ \\text{LASSO} \\rightarrow \\arg\\min_{a, b} \\left\\{ \\sum_i \\left( y_i - a - b \\cdot x_i \\right)^2 + \\lambda \\cdot | b |  \\right\\}$$\n",
    "\n",
    "For multivariate data, this becomes (for those familiar with vector norms):\n",
    "\n",
    "$$ \\text{LASSO} \\rightarrow \\arg\\min_{\\beta} \\left\\{ || y - \\beta X ||_2^2 + \\lambda \\cdot || b ||_1  \\right\\}$$\n",
    "\n",
    "And finally, the elastic net is given by:\n",
    "\n",
    "$$ \\text{ELASTIC NET} \\rightarrow \\arg\\min_{\\beta} \\left\\{ || y - \\beta X ||_2^2 +\n",
    "   \\lambda \\cdot \\rho || b ||_1 + \\lambda \\cdot (1 - \\rho) || b ||_2^2  \\right\\}$$\n",
    "\n",
    "The details for us in this course are not important; what should be taken away is that we\n",
    "have a model that forces slope parameters to be zero unless they are particularly useful\n",
    "in the prediction task. It turns out that this is particularly useful for text prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a logistic elasic net according to the same approach used in other sklearn\n",
    "estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogitNet(alpha=1, cut_point=1.0, fit_intercept=True, lambda_path=None,\n",
       "     max_iter=100000, min_lambda_ratio=0.0001, n_jobs=1, n_lambda=100,\n",
       "     n_splits=3, random_state=None, scoring=None, standardize=True,\n",
       "     tol=1e-07, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnet = glmnet.LogitNet()\n",
    "lnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as with other estimators, we fit the data using the `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogitNet(alpha=1, cut_point=1.0, fit_intercept=True, lambda_path=None,\n",
       "     max_iter=100000, min_lambda_ratio=0.0001, n_jobs=1, n_lambda=100,\n",
       "     n_splits=3, random_state=None, scoring=None, standardize=True,\n",
       "     tol=1e-07, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnet.fit(tf_mat, y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as constructing predictions using the predict function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lnet.predict(tf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And see how well it performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9264757864969954"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_vals, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the selected parameters\n",
    "\n",
    "More than the model itself, though, the most interesting thing about the elastic\n",
    "net is seeing what variables were choosen by the algorithm. To start, it is helpful\n",
    "to wrap up a list that matches each word to its coefficent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1850', 0.0),\n",
       " ('1867', 0.0),\n",
       " ('1869', 0.0),\n",
       " ('1870s', 0.0),\n",
       " ('1878', 0.0),\n",
       " ('1885', 0.0),\n",
       " ('1886', 0.0),\n",
       " ('1890', 0.0),\n",
       " ('1922', 0.0),\n",
       " ('24', 0.0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = list(zip(words, lnet.coef_[0, :]))\n",
    "vals[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, sort the results by the coefficent and show the non-zero\n",
    "values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poet            =>     0.79\n",
      "poetry          =>     0.33\n",
      "fiction         =>    -0.00\n",
      "author          =>    -0.01\n",
      "novel           =>    -0.13\n",
      "novels          =>    -0.19\n",
      "novelist        =>    -0.50\n"
     ]
    }
   ],
   "source": [
    "for x in sorted(vals, key=lambda x: x[1], reverse=True):\n",
    "    if x[1] != 0:\n",
    "        print(\"{0:15s} => {1: 8.2f}\".format(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that poets are coded as 1's and novelists as 0's;\n",
    "so positive terms are correlated with poets and negatives are novelists.\n",
    "Do the results make sense to you?\n",
    "\n",
    "The value for $\\lambda$ in the elastic net is choosen by trying up to 100\n",
    "values and using a technique for determining which one is best. Sometimes \n",
    "it is also useful to look at non-optimal values, for example if the optimal\n",
    "output contains too many or too few terms to understand the structure of\n",
    "the data. Here, we grab the 30th largest value of the tuning parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139             =>     1.06\n",
      "poet            =>     0.86\n",
      "poetry          =>     0.37\n",
      "poems           =>     0.00\n",
      "fiction         =>    -0.01\n",
      "author          =>    -0.03\n",
      "starring        =>    -0.03\n",
      "novel           =>    -0.14\n",
      "novels          =>    -0.21\n",
      "novelist        =>    -0.55\n"
     ]
    }
   ],
   "source": [
    "vals = list(zip(words, lnet.coef_path_[0, :, 26]))\n",
    "for x in sorted(vals, key=lambda x: x[1], reverse=True):\n",
    "    if x[1] != 0:\n",
    "        print(\"{0:15s} => {1: 8.2f}\".format(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the new values make sense to you? Do any seem superfluous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another application\n",
    "\n",
    "Let's use the same dataset applied to a different respones variable: whether\n",
    "the page has been translated into German. Note that positive values are associated\n",
    "with translated pages and negative values are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "married         =>     0.15\n",
      "pulitzer        =>     0.13\n",
      "wrote           =>     0.04\n",
      "novels          =>     0.04\n",
      "novel           =>     0.03\n",
      "years           =>     0.03\n",
      "time            =>     0.02\n",
      "best            =>     0.02\n",
      "short           =>     0.01\n",
      "adapted         =>     0.01\n",
      "film            =>     0.00\n",
      "won             =>     0.00\n"
     ]
    }
   ],
   "source": [
    "lan_version = np.array(['de' in x for x in wcorp.meta['langs']], dtype=np.int)\n",
    "\n",
    "lnet = glmnet.LogitNet()\n",
    "lnet.fit(tf_mat, lan_version)\n",
    "\n",
    "vals = list(zip(words, lnet.coef_[0, :]))\n",
    "for x in sorted(vals, key=lambda x: x[1], reverse=True):\n",
    "    if x[1] != 0:\n",
    "        print(\"{0:15s} => {1: 8.2f}\".format(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for French:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "married         =>     0.11\n",
      "won             =>     0.07\n",
      "novels          =>     0.06\n",
      "adapted         =>     0.06\n",
      "wrote           =>     0.05\n",
      "time            =>     0.04\n",
      "novel           =>     0.04\n",
      "short           =>     0.02\n",
      "best            =>     0.01\n",
      "years           =>     0.01\n",
      "film            =>     0.01\n",
      "fiction         =>     0.01\n",
      "father          =>     0.00\n"
     ]
    }
   ],
   "source": [
    "lan_version = np.array(['fr' in x for x in wcorp.meta['langs']], dtype=np.int)\n",
    "\n",
    "lnet = glmnet.LogitNet()\n",
    "lnet.fit(tf_mat, lan_version)\n",
    "\n",
    "vals = list(zip(words, lnet.coef_[0, :]))\n",
    "for x in sorted(vals, key=lambda x: x[1], reverse=True):\n",
    "    if x[1] != 0:\n",
    "        print(\"{0:15s} => {1: 8.2f}\".format(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once more, in Chinese:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years           =>     0.08\n",
      "time            =>     0.04\n",
      "wrote           =>     0.04\n",
      "father          =>     0.03\n",
      "best            =>     0.02\n",
      "life            =>     0.02\n",
      "short           =>     0.01\n",
      "writer          =>     0.01\n",
      "novel           =>     0.01\n",
      "novels          =>     0.01\n",
      "writing         =>     0.00\n",
      "won             =>     0.00\n",
      "awarded         =>     0.00\n",
      "written         =>     0.00\n"
     ]
    }
   ],
   "source": [
    "lan_version = np.array(['zh' in x for x in wcorp.meta['langs']], dtype=np.int)\n",
    "\n",
    "lnet = glmnet.LogitNet()\n",
    "lnet.fit(tf_mat, lan_version)\n",
    "\n",
    "vals = list(zip(words, lnet.coef_[0, :]))\n",
    "for x in sorted(vals, key=lambda x: x[1], reverse=True):\n",
    "    if x[1] != 0:\n",
    "        print(\"{0:15s} => {1: 8.2f}\".format(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What patterns do you see in the data here? **Does it tell you anything about the\n",
    "nature of Wikipedia?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also found predicting whether a page has more than 2 images to be similarly\n",
    "interesting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cemetery        =>     0.33\n",
      "1866            =>     0.22\n",
      "1886            =>     0.15\n",
      "famous          =>     0.10\n",
      "buried          =>     0.10\n",
      "married         =>     0.08\n",
      "entered         =>     0.08\n",
      "semi            =>     0.07\n",
      "wrote           =>     0.06\n",
      "1873            =>     0.06\n",
      "died            =>     0.04\n",
      "public          =>     0.04\n",
      "authors         =>     0.04\n",
      "father          =>     0.04\n",
      "children        =>     0.04\n",
      "called          =>     0.03\n",
      "war             =>     0.03\n",
      "years           =>     0.03\n",
      "1907            =>     0.03\n",
      "life            =>     0.02\n",
      "presented       =>     0.02\n",
      "works           =>     0.02\n",
      "needed          =>     0.02\n",
      "multiple        =>     0.02\n",
      "century         =>     0.02\n",
      "well            =>     0.01\n",
      "received        =>     0.01\n",
      "earth           =>     0.01\n",
      "age             =>     0.01\n",
      "included        =>     0.01\n",
      "best            =>     0.01\n",
      "elected         =>     0.01\n",
      "series          =>     0.01\n",
      "early           =>     0.01\n",
      "fiction         =>     0.00\n",
      "death           =>     0.00\n",
      "literature      =>     0.00\n",
      "author          =>     0.00\n",
      "school          =>     0.00\n",
      "press           =>    -0.01\n"
     ]
    }
   ],
   "source": [
    "image_flag = wcorp.meta['num_images'].values > 2\n",
    "\n",
    "lnet = glmnet.LogitNet()\n",
    "lnet.fit(tf_mat, image_flag)\n",
    "\n",
    "vals = list(zip(words, lnet.coef_[0, :]))\n",
    "for x in sorted(vals, key=lambda x: x[1], reverse=True):\n",
    "    if x[1] != 0:\n",
    "        print(\"{0:15s} => {1: 8.2f}\".format(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Any take aways from this set of words?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
